{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ysMUOdDHnbw5CAGyjUHbnzGoj7fZzLkh",
      "authorship_tag": "ABX9TyMa7F5X7f1N/djW48YVN12P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/646e62/citation-generator/blob/main/canlii_skca_extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SKCA extractor\n",
        "\n",
        "## HTML to Markdown\n",
        "\n",
        "Although there may be some clues to be found in the way the original CanLII document is structured, it contains an overwhelming amount of data. A lot of that data is unhelpful noise.\n",
        "\n",
        "As it turned out, the HTML to Markdown converter ``html2text`` was able to ignore that noise and pick out multiple key features (document structure, where paragraphs actually start and stop, etc). Should the need for fine tuning arise, there may need to be some HTML pre-processing. But for the time being, the Markdown document is more than sufficient for the program's purpose.\n",
        "\n",
        "## Metadata\n",
        "\n",
        "After creating the Markdown document and splitting it into its natural paragraphs, it became apparent that paragraph[0] contained a fair bit of metadata that could be extracted with some text processing.\n",
        "\n",
        "Although SKCA metadata isn't as extensive or specific as some other jurisdictions, it is informative. Specifically, the fact that SKCA outlines case features like \"disposition\" in easily-located plain text make these documents easy to work with.\n",
        "\n",
        "## Document structure\n",
        "\n",
        "Another thing that became apparent after creating the Markdown document was the fact that ``html2text`` did a good job of capturing document structure.\n",
        "\n",
        "## Text analysis\n",
        "\n",
        "## TODO\n",
        "\n",
        "* Appellate\n",
        "    * Good metadata\n",
        "        * BCCA\n",
        "        * SKCA\n",
        "        * QCCA\n",
        "        * NBCA\n",
        "        * NSCA\n",
        "        * PECA\n",
        "        * YKCA\n",
        "    * Viable metadata\n",
        "        * NLCA\n",
        "    * Inadequate metadata\n",
        "        * ABCA\n",
        "        * MBCA\n",
        "        * ONCA\n",
        "        * NWTCA\n",
        "        * NUCA\n"
      ],
      "metadata": {
        "id": "W_Kahvi0yRFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and installations\n",
        "\n",
        "### html2text\n",
        "\n",
        "The extractor uses html2text-2020.1.16 to generate Markdown files."
      ],
      "metadata": {
        "id": "Cph3w6TYfSFd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgJ-lRPtHIPZ",
        "outputId": "568d80c3-8337-458d-ab7d-6b94ee8e83c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: html2text in /usr/local/lib/python3.10/dist-packages (2020.1.16)\n"
          ]
        }
      ],
      "source": [
        "!pip install html2text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import html2text\n",
        "import re\n",
        "\n",
        "from typing import Dict, List, Union\n",
        "from datetime import datetime\n"
      ],
      "metadata": {
        "id": "vPUeRY6MewLp"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Patterns file\n",
        "\n",
        "This program is designed to work with decisions published on CanLII. Every such decision contains consistent metacontent that the UNWANTED_PATTERNS constant captures via regex.\n",
        "\n",
        "Although I print the Markdown file throughout this working document for troubleshooting purposes, the final version of the program will not print or return the Markdown file to the user.\n",
        "\n",
        "After dealing with the universal metacontent, the program will need to account for the metadata and metadata structures added by the SKCA. Unlike commercial products like WL and QL, CanLII doesn't use a universal format for its decisions. Rather, it appears to allow individual courts to structure their documents as they see fit. Although commendable from a \"marketplace of ideas\" perspective, it makes it more difficult to access metadata and other such content in a consistent way. Rather than developing\n",
        "\n",
        "Data from the SKCA is both immediately important to me and\n",
        "\n",
        "Because SKCA structures its decision metadata in a fairly predictable and regimented way, the same regex-based approach can be used to separate the data from"
      ],
      "metadata": {
        "id": "6OQ_4grgfCt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "UNWANTED_PATTERNS = [\n",
        "    r'\\[ !\\[CanLII Logo\\]\\(.+?\\) \\]\\(.+?\\)',\n",
        "    r'\\[Home\\]\\(.+?\\) › .+?CanLII\\)',\n",
        "    r'Loading paragraph markers __',\n",
        "    r'\\* Document',\n",
        "    r'\\* History  __',\n",
        "    r'\\* Cited documents  __',\n",
        "    r'\\* Treatment  __',\n",
        "    r'\\* CanLII Connects  __',\n",
        "    r'Citations  __',\n",
        "    r'Discussions  __',\n",
        "    r'Unfavourable mentions  __',\n",
        "    r'\\nExpanded Collapsed\\n'\n",
        "]\n",
        "\n",
        "# Metadata patterns for SKCA decisions on CanLII after 2015\n",
        "\n",
        "SKCA_2015_METADATA_PATTERNS = {\n",
        "    'between': r'Between:(.*?)(?=Before:)',\n",
        "    'disposition': r'Disposition:\\s*(.+?)\\s{2,}',\n",
        "    'on_appeal_from': r'On appeal from:\\s*(.+?)\\s{2,}',\n",
        "    'appeal_heard': r'Appeal heard:\\s*(.+?)\\s{2,}',\n",
        "    'application_heard': r'Application heard:\\s*([\\w\\s,]+)'\n",
        "}\n",
        "\n",
        "BASE_ROLES = [\n",
        "    'plaintiff', 'plaintiffs',\n",
        "    'respondent', 'respondents',\n",
        "    'appellant', 'appellants',\n",
        "    'applicant', 'applicants'\n",
        "]\n",
        "\n",
        "# Generate combinations with brackets and slashes\n",
        "ROLES = BASE_ROLES + [\n",
        "    f\"({role})\" for role in BASE_ROLES\n",
        "] + [\n",
        "    f\"{role1}/{role2}\" for role1 in BASE_ROLES for role2 in BASE_ROLES\n",
        "]"
      ],
      "metadata": {
        "id": "DIVEUTE6ewT9"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HTML to MD functions\n",
        "\n"
      ],
      "metadata": {
        "id": "H1UC997rtRjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def html_to_markdown(html_content: str) -> str:\n",
        "    \"\"\"\n",
        "    Converts HTML content to its markdown representation.\n",
        "\n",
        "    Args:\n",
        "        html_content (str): The input HTML content.\n",
        "\n",
        "    Returns:\n",
        "        str: The converted markdown content.\n",
        "    \"\"\"\n",
        "\n",
        "    h = html2text.HTML2Text()\n",
        "    h.ignore_links = False\n",
        "    return h.handle(html_content)\n",
        "\n",
        "def convert_file(html_filepath: str, markdown_filepath: str) -> None:\n",
        "    \"\"\"\n",
        "    Converts an HTML file to a markdown file.\n",
        "\n",
        "    Args:\n",
        "        html_filepath (str): Path to the input HTML file.\n",
        "        markdown_filepath (str): Path to the output markdown file.\n",
        "    \"\"\"\n",
        "\n",
        "    with open(html_filepath, 'r', encoding='utf-8') as file:\n",
        "        html_content = file.read()\n",
        "\n",
        "    markdown_content = html_to_markdown(html_content)\n",
        "    refined_markdown_content = refine_markdown(markdown_content)\n",
        "\n",
        "    with open(markdown_filepath, 'w', encoding='utf-8') as file:\n",
        "        file.write(refined_markdown_content)\n",
        "\n",
        "def refine_markdown(md_content: str, unwanted_patterns: List[str] = UNWANTED_PATTERNS) -> str:\n",
        "    \"\"\"\n",
        "    Refines the markdown content by making specific replacements and deletions.\n",
        "\n",
        "    Args:\n",
        "        md_content (str): The input markdown content.\n",
        "        unwanted_patterns (List[str], optional): List of regex patterns to be removed from the content. Defaults to UNWANTED_PATTERNS.\n",
        "\n",
        "    Returns:\n",
        "        str: The refined markdown content.\n",
        "    \"\"\"\n",
        "\n",
        "    # Replace only the first occurrence of '## ' with '# '\n",
        "    md_content = md_content.replace('## ', '# ', 1)\n",
        "\n",
        "    # Remove hard line breaks after labels\n",
        "    md_content = re.sub(r'Date:\\s*\\n', 'Date: ', md_content)\n",
        "    md_content = re.sub(r'File number:\\s*\\n', 'File number: ', md_content)\n",
        "    md_content = re.sub(r'Citation:\\s*\\n', 'Citation: ', md_content)\n",
        "\n",
        "    # Remove unwanted sections from the captured content\n",
        "    for pattern in unwanted_patterns:\n",
        "        md_content = re.sub(pattern, '', md_content)\n",
        "\n",
        "    # Define the pattern to remove the footer and everything that follows\n",
        "    footer_start = \"Back to top\"\n",
        "    if footer_start in md_content:\n",
        "        md_content = md_content.split(footer_start)[0]\n",
        "\n",
        "    # Remove patterns like \"---|---\" and \"---|---|---|---\"\n",
        "    md_content = re.sub(r'---(\\|---)+', '\\n', md_content)\n",
        "\n",
        "    # Replace the character `|` with an empty newline\n",
        "    md_content = md_content.replace('|', '\\n')\n",
        "\n",
        "    # Replace \"[__PDF]\" with \"[PDF]\"\n",
        "    md_content = md_content.replace('[__  PDF]', '[PDF]')\n",
        "\n",
        "    return md_content.strip()\n"
      ],
      "metadata": {
        "id": "rCIqiuAUHIfU"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text refining functions"
      ],
      "metadata": {
        "id": "ahRpCO4Kxf--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_standard_date(date_string: str) -> str:\n",
        "    \"\"\"\n",
        "    Converts a date string to a standard format YYYY-MM-DD.\n",
        "\n",
        "    Args:\n",
        "        date_string (str): Input date string.\n",
        "\n",
        "    Returns:\n",
        "        str: Date in standard format.\n",
        "    \"\"\"\n",
        "    # Define the expected date formats for the input strings\n",
        "    date_formats = [\"%Y-%m-%d\", \"%B %d, %Y\"]\n",
        "\n",
        "    for date_format in date_formats:\n",
        "        try:\n",
        "            # Parse the string into a datetime object\n",
        "            date_obj = datetime.strptime(date_string, date_format)\n",
        "            # Return the formatted string\n",
        "            return date_obj.strftime(\"%Y-%m-%d\")\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "    # If all parsing attempts fail, return the original string\n",
        "    return date_string\n",
        "\n",
        "\n",
        "def clean_markdown(filename):\n",
        "    \"\"\"Cleans markdown in the given file.\n",
        "\n",
        "    Args:\n",
        "        filename: The name of the file to clean.\n",
        "\n",
        "    Returns:\n",
        "        A markdown file _sans_ extraneous whitespace\n",
        "    \"\"\"\n",
        "\n",
        "    with open(filename, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    cleaned_lines = []\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        line = line.replace(\"_\", \"\")\n",
        "        cleaned_lines.append(line)\n",
        "\n",
        "    return '\\n'.join(cleaned_lines)\n"
      ],
      "metadata": {
        "id": "453GjvyVxgzU"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CanLII metadata extractor\n",
        "\n",
        "Should be the same across all CanLII cases. Doesn't contain much information."
      ],
      "metadata": {
        "id": "8opW5jQm_acI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def capture_canlii_metadata(md_content: str) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Captures specific metadata (date, file number, citation) from markdown content.\n",
        "\n",
        "    Args:\n",
        "        md_content (str): The input markdown content.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, str]: A dictionary containing captured metadata.\n",
        "    \"\"\"\n",
        "\n",
        "    metadata = {}\n",
        "\n",
        "    # Capture date\n",
        "    date_match = re.search(r'Date: (\\d{4}-\\d{2}-\\d{2})', md_content)\n",
        "    if date_match:\n",
        "        metadata['date'] = date_match.group(1)\n",
        "\n",
        "    # Capture file number\n",
        "    file_match = re.search(r'File number: ([A-Z0-9]+)', md_content)\n",
        "    if file_match:\n",
        "        metadata['file_number'] = file_match.group(1)\n",
        "\n",
        "    # Capture citation\n",
        "    citation_pattern = r'Citation: (.+?)<<(.+?)>>, retrieved\\s+on\\s+(\\d{4}-\\d{2}-\\d{2})'\n",
        "    citation_match = re.search(citation_pattern, md_content, re.DOTALL)\n",
        "    if citation_match:\n",
        "        metadata['citation'] = f\"{citation_match.group(1).strip()} {citation_match.group(2)} retrieved on {citation_match.group(3)}\"\n",
        "\n",
        "    return metadata\n"
      ],
      "metadata": {
        "id": "RtQxzHFyOhsF"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SKCA metadata extractor\n",
        "\n"
      ],
      "metadata": {
        "id": "2RSMxfSGkWG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_metadata(pattern: str, md_content: str, known_patterns: list) -> list:\n",
        "    \"\"\"\n",
        "    Extract metadata using the provided pattern from md_content.\n",
        "\n",
        "    Args:\n",
        "    - pattern: The regex pattern to search for.\n",
        "    - md_content: The content to search within.\n",
        "    - known_patterns: Known metadata patterns to consider in lookahead.\n",
        "\n",
        "    Returns:\n",
        "    - A list of names found based on the pattern.\n",
        "    \"\"\"\n",
        "    match = re.search(pattern, md_content, re.DOTALL | re.IGNORECASE)\n",
        "    if match:\n",
        "        cleaned_string = re.sub(r'\\n+', ' ', match.group(1)).strip()\n",
        "        names_list = [name for name in cleaned_string.split('  ') if name]\n",
        "        return names_list\n",
        "    return []\n",
        "\n",
        "def extract_parties(md_content: str) -> list:\n",
        "    \"\"\"\n",
        "    Extract parties from md_content.\n",
        "\n",
        "    Args:\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    role_pattern = re.compile('|'.join(map(re.escape, ROLES)), re.IGNORECASE)\n",
        "\n",
        "    match = re.search(SKCA_2015_METADATA_PATTERNS['between'], md_content, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        between_values = [line.strip() for line in match.group(1).strip().split('\\n')\n",
        "                        if line.strip() and line.strip().lower() != 'and']\n",
        "\n",
        "        parties_list = []\n",
        "        prev_party = None\n",
        "        current_role = \"\"\n",
        "        for line in between_values:\n",
        "            if role_pattern.search(line):  # Using regex search here\n",
        "                if current_role:\n",
        "                    current_role += \" \" + line\n",
        "                else:\n",
        "                    current_role = line\n",
        "            else:\n",
        "                if prev_party and current_role:\n",
        "                    parties_list.append({'party': prev_party, 'role': current_role})\n",
        "                    current_role = \"\"\n",
        "                prev_party = line\n",
        "\n",
        "        # Handle the last party-role pair\n",
        "        if prev_party and current_role:\n",
        "            parties_list.append({'party': prev_party, 'role': current_role})\n",
        "\n",
        "        return parties_list\n",
        "\n",
        "def extract_counsel(md_content: str) -> list:\n",
        "    \"\"\"\n",
        "    Extract counsel from md_content.\n",
        "\n",
        "    Args:\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "   # Split the string at \"Counsel:\"\n",
        "    parts = s.split('Counsel:', 1)\n",
        "\n",
        "    # If there's no \"Counsel:\" or nothing after it, return an empty list\n",
        "    if len(parts) < 2:\n",
        "        return []\n",
        "\n",
        "    # Split the remaining string by lines and strip whitespace from each line\n",
        "    lines = [line.strip() for line in parts[1].split('\\n')]\n",
        "\n",
        "    # Filter out empty lines\n",
        "    lines = [line for line in lines if line]\n",
        "\n",
        "    # Process each line to split on \"and\" if necessary and keep lines with \"for\"\n",
        "    final_lines = []\n",
        "    for line in lines:\n",
        "        if \" for \" in line:\n",
        "            names = line.split(\" and \")\n",
        "            if len(names) > 1:\n",
        "                for_clause = names[-1].split(\" for \", 1)[-1]  # e.g., \"the Appellant\"\n",
        "                for name in names:\n",
        "                    if \" for \" not in name:\n",
        "                        final_lines.append(name.strip() + \" for \" + for_clause)\n",
        "                    else:\n",
        "                        final_lines.append(name.strip())\n",
        "            else:\n",
        "                final_lines.append(line)\n",
        "\n",
        "    return final_lines\n",
        "\n",
        "def extract_counsel_legacy(md_content: str) -> list:\n",
        "    \"\"\"\n",
        "    Extract counsel from md_content.\n",
        "\n",
        "    Args:\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Extracting counsel as a special case:\n",
        "    counsel_pattern = (\n",
        "        r'(?:'                   # Non-capturing group start\n",
        "        r'[\\w\\s-]+'              # Matches word characters, spaces, and hyphens\n",
        "        r'(?:, [KQ].C.)?'        # Optionally matches ', K.C.' or ', Q.C.'\n",
        "        r' and '                 # Matches ' and '\n",
        "        r')?'                    # End of non-capturing group, which is optional\n",
        "        r'[\\w\\s-]+'              # Matches word characters, spaces, and hyphens again\n",
        "        r'(?:, [KQ].C.)?'        # Optionally matches ', K.C.' or ', Q.C.' again\n",
        "        r',?'                    # Optional comma\n",
        "        r' for the '             # Matches ' for the '\n",
        "        r'[\\w\\s\\-A-Za-z]+'       # Matches word characters, spaces, hyphens, and English letters\n",
        "    )\n",
        "\n",
        "    counsel_string = re.findall(counsel_pattern, md_content)\n",
        "\n",
        "    # Remove whitespace\n",
        "    cleaned_counsel = re.sub(r'\\n', '', counsel_string[0])\n",
        "    cleaned_counsel = re.sub(r' +', ' ', cleaned_counsel)\n",
        "    cleaned_counsel = cleaned_counsel.strip()\n",
        "\n",
        "    # Placeholder for our final, cleaned-up information\n",
        "    good_information = \"\"\n",
        "\n",
        "    while True:\n",
        "        match = re.search(r'(.*?)(for the \\w+)', cleaned_counsel)\n",
        "        if match:\n",
        "            # Add the matched segment to our good information\n",
        "            good_information += match.group(1) + match.group(2) + \" \"\n",
        "            # Remove the processed segment from cleaned_counsel\n",
        "            cleaned_counsel = cleaned_counsel.replace(match.group(0), '', 1)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # Optionally, trim any trailing spaces\n",
        "    good_information = good_information.strip()\n",
        "\n",
        "    # Find all occurrences of 'for the [word]' and split the string based on them\n",
        "    roles = re.findall(r'for the \\w+', good_information)\n",
        "    segments = re.split(r'for the \\w+', good_information)\n",
        "\n",
        "    final_list = []\n",
        "    for role, segment in zip(roles, segments):\n",
        "        # Updated regex split logic\n",
        "        names = [name.strip() for name in re.split(r',? and |,(?![\\s]?[KQ]\\.C\\.)', segment)]\n",
        "        for name in names:\n",
        "            if name:  # Ensure we don't append empty names\n",
        "                final_list.append(name + ' ' + role)\n",
        "\n",
        "    return final_list\n",
        "\n",
        "\n",
        "def extract_judges(md_content: str) -> list:\n",
        "    \"\"\"\n",
        "    Extract judges from md_content.\n",
        "\n",
        "    Args:\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "def capture_skca_metadata(md_content: str) -> Dict[str, Union[str, List[str]]]:\n",
        "    \"\"\"\n",
        "    Captures specific secondary metadata from markdown content.\n",
        "\n",
        "    Args:\n",
        "        md_content (str): The input markdown content.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Union[str, List[str]]]: A dictionary containing captured metadata.\n",
        "    \"\"\"\n",
        "    metadata = {}\n",
        "    metadata_patterns = SKCA_2015_METADATA_PATTERNS\n",
        "\n",
        "    # Extracting special case lists\n",
        "    for key, pattern in metadata_patterns.items():\n",
        "        match = re.search(\n",
        "            pattern,\n",
        "            md_content,\n",
        "            re.DOTALL | re.IGNORECASE\n",
        "        )\n",
        "        try:\n",
        "            if match:\n",
        "                metadata[key] = ' '.join(match.group(1).split()).strip()\n",
        "                print(metadata[key] + \"\\n\")\n",
        "        except IndexError:\n",
        "            pass\n",
        "\n",
        "    metadata['between'] = extract_parties(md_content)\n",
        "    metadata['counsel'] = extract_counsel(md_content)\n",
        "\n",
        "    # Extract the date components and convert to standard format\n",
        "    if 'application_heard' in metadata:\n",
        "        metadata['application_heard'] = ' '.join(metadata['application_heard'].split()[:3])\n",
        "        metadata['application_heard'] = convert_to_standard_date(metadata['application_heard'])\n",
        "\n",
        "    if 'appeal_heard' in metadata:\n",
        "        metadata['appeal_heard'] = convert_to_standard_date(metadata['appeal_heard'])\n",
        "\n",
        "    # Testing for multiple judge detection\n",
        "\n",
        "    known_patterns = [\n",
        "        r'Docket:',\n",
        "        r'Citation:',\n",
        "        r'Date:',\n",
        "        r'Between:',\n",
        "        r'Before:',\n",
        "        r'Disposition:',\n",
        "        r'Written reasons by:',\n",
        "        r'In concurrence:',\n",
        "        r'In dissent:',\n",
        "        r'On Application From:',\n",
        "        r'Application Heard:'\n",
        "        r'On appeal from:',\n",
        "        r'Appeal heard:',\n",
        "        r'Counsel:',\n",
        "    ]\n",
        "\n",
        "    # Patterns to check\n",
        "    patterns_to_check = {\n",
        "        'written_reasons_by': r'Written reasons by:\\s*(.+?)(?=\\s{2,}(?:' + '|'.join(known_patterns) + r')|$)',\n",
        "        'in_concurrence': r'In concurrence:\\s*(.+?)(?=\\s{2,}(?:' + '|'.join(known_patterns) + r')|$)',\n",
        "        'in_dissent': r'In dissent:\\s*(.+?)(?=\\s{2,}(?:' + '|'.join(known_patterns) + r')|$)'\n",
        "    }\n",
        "\n",
        "    # Iterate over each pattern, extracting the metadata and storing in the 'metadata' dictionary\n",
        "    for key, pattern in patterns_to_check.items():\n",
        "        metadata[key] = extract_metadata(pattern, md_content, known_patterns)\n",
        "\n",
        "    return metadata\n"
      ],
      "metadata": {
        "id": "sCMXJoy9cnH4"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_paragraphs(md_content):\n",
        "    # Split the content using the '--' pattern\n",
        "    paragraphs = md_content.split('\\n__\\n')\n",
        "\n",
        "    # Strip leading and trailing whitespace from each paragraph\n",
        "    paragraphs = [p.strip() for p in paragraphs if p.strip()]\n",
        "\n",
        "    return paragraphs\n"
      ],
      "metadata": {
        "id": "PdQtiqFG9v7I"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neutral_citation = \"2023skca101\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "SEiA8ccGvH6K"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    html_filepath = f\"{neutral_citation}.html\"\n",
        "    markdown_filepath = f\"{neutral_citation}.md\"\n",
        "\n",
        "    with open(html_filepath, 'r', encoding='utf-8') as file:\n",
        "        html_content = file.read()\n",
        "\n",
        "    markdown_content = html_to_markdown(html_content)\n",
        "    refined_markdown_content = refine_markdown(markdown_content)\n",
        "    paragraphs = extract_paragraphs(refined_markdown_content)\n",
        "    canlii_metadata = capture_canlii_metadata(paragraphs[0])\n",
        "    skca_metadata = capture_skca_metadata(paragraphs[0])\n",
        "\n",
        "    with open(markdown_filepath, 'w', encoding='utf-8') as file:\n",
        "        file.write(refined_markdown_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E60B5xHv53NO",
        "outputId": "1f90b9c9-51be-4f9e-aa7b-4f953b769b8c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mitchell Owston Appellant And His Majesty the King Respondent\n",
            "\n",
            "Appeal allowed; acquittal entered\n",
            "\n",
            "CRM 304 of 2019 (Sask QB), Regina\n",
            "\n",
            "September 9, 2022\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in canlii_metadata.items():\n",
        "    print(key + \": \", value)\n",
        "\n",
        "for key, value in skca_metadata.items():\n",
        "    print(key + \": \", value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gxCtDxH93Bv",
        "outputId": "8e4594d1-81f7-491a-8d51-f57290bbd873"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "date:  2023-08-31\n",
            "file_number:  CACR3511\n",
            "citation:  R v Owston, 2023 SKCA 101 (CanLII), https://canlii.ca/t/k005d retrieved on 2023-10-04\n",
            "between:  [{'party': 'Mitchell Owston', 'role': 'Appellant'}, {'party': 'His Majesty the King', 'role': 'Respondent'}]\n",
            "disposition:  Appeal allowed; acquittal entered\n",
            "on_appeal_from:  CRM 304 of 2019 (Sask QB), Regina\n",
            "appeal_heard:  2022-09-09\n",
            "counsel:  ['\\n\\n\\n\\n\\nBrian Pfefferle, K.C.', ' and Thomas Hynes for the Appellant  \\n  \\n\\n\\n\\n\\n\\nGrace Hession David for the Respondent  \\n  \\n\\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n\\n\\n  \\n\\nThe Court\\n\\n']\n",
            "written_reasons_by:  ['The Court', 'On appeal from: CRM 304 of 2019 (Sask QB), Regina']\n",
            "in_concurrence:  []\n",
            "in_dissent:  []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(paragraphs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81jExQB9bEOf",
        "outputId": "7d77898a-e807-4480-c0e3-5a39c888e824"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Home](/en/) › [Saskatchewan](/en/sk/) › [Court of Appeal for\n",
            "Saskatchewan](/en/sk/skca/) › 2023 SKCA 101 (CanLII)\n",
            "\n",
            "\n",
            "\n",
            "# R v Owston, 2023 SKCA 101 (CanLII)\n",
            "\n",
            "  \n",
            "  \n",
            "  \n",
            "   \n",
            "  \n",
            "\n",
            "[PDF](/en/sk/skca/doc/2023/2023skca101/2023skca101.pdf)\n",
            "\n",
            "Date: 2023-08-31\n",
            "\n",
            "File number: CACR3511\n",
            "\n",
            "Citation: R v Owston, 2023 SKCA 101 (CanLII), <<https://canlii.ca/t/k005d>>, retrieved\n",
            "on 2023-10-04\n",
            "\n",
            "    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  \n",
            "  \n",
            "\n",
            "  \n",
            "  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Restriction on Publication\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "An order has been made in accordance with [s.\n",
            "486.4(1)](/en/ca/laws/stat/rsc-1985-c-c-46/latest/rsc-1985-c-c-46.html#sec486.4subsec1_smooth)\n",
            "of the _[Criminal\n",
            "Code](/en/ca/laws/stat/rsc-1985-c-c-46/latest/rsc-1985-c-c-46.html)_ directing\n",
            "that any information identifying the complainant shall not be published.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  \n",
            "  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  \n",
            "  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  \n",
            "  \n",
            "Court of Appeal for Saskatchewan\n",
            "\n",
            "Docket: CACR3511\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Citation: _R v Owston_ , 2023 SKCA 101  \n",
            "  \n",
            "Date: 2023-08-31  \n",
            "  \n",
            "Between:  \n",
            "  \n",
            "Mitchell Owston  \n",
            "  \n",
            "Appellant  \n",
            "  \n",
            "And  \n",
            "  \n",
            "His Majesty the King  \n",
            "  \n",
            "Respondent  \n",
            "  \n",
            "Before:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Schwann, Barrington-Foote and McCreary JJ.A.  \n",
            "  \n",
            "Disposition:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Appeal allowed; acquittal entered  \n",
            "  \n",
            "Written reasons by:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The Court  \n",
            "  \n",
            "On appeal from:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CRM 304 of 2019 (Sask QB), Regina  \n",
            "  \n",
            "Appeal heard:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "September 9, 2022  \n",
            "  \n",
            "Counsel:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Brian Pfefferle, K.C. and Thomas Hynes for the Appellant  \n",
            "  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Grace Hession David for the Respondent  \n",
            "  \n",
            "\n",
            "  \n",
            "  \n",
            "  \n",
            "  \n",
            "  \n",
            "  \n",
            "  \n",
            "\n",
            "\n",
            "  \n",
            "\n",
            "The Court\n",
            "\n",
            "# I.                  INTRODUCTION\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_counsel(counsel_string: str) -> list:\n",
        "    counsel_list = []\n",
        "\n",
        "    # 1. Self-representation: Using non-capturing group\n",
        "    self_rep_pattern = r'[\\w\\s-]+ on (?:his|her) own behalf'\n",
        "    self_rep_matches = re.findall(self_rep_pattern, counsel_string)\n",
        "    counsel_list.extend(self_rep_matches)  # directly append matched strings\n",
        "\n",
        "    # 2. Names followed by \", K.C.\" or \", Q.C.\"\n",
        "    kc_qc_pattern = r'[\\w\\s-]+, [KQ]\\.C\\.'\n",
        "    kc_qc_matches = re.findall(kc_qc_pattern, counsel_string)\n",
        "    counsel_list.extend(kc_qc_matches)\n",
        "\n",
        "    # 3. Names with \"for the [role]\"\n",
        "    role_pattern = r'[\\w\\s-]+(?= for the [\\w\\s\\-\\'A-Za-z]+) for the [\\w\\s\\-\\'A-Za-z]+'\n",
        "    role_matches = re.findall(role_pattern, counsel_string)\n",
        "    counsel_list.extend(role_matches)\n",
        "\n",
        "    return counsel_list\n",
        "\n",
        "# Test\n",
        "test_string = \"\"\"\n",
        "Counsel:\n",
        "\n",
        "Michael Taylor on his own behalf\n",
        "Wade McBride, K.C., and Carlene Ready for the Respondent\n",
        "Lisa Watson for Saskatchewan Lawyers' Insurance Association Inc.\n",
        "\"\"\"\n",
        "\n",
        "print(extract_counsel(test_string))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llS8Nzdx8gHK",
        "outputId": "9ce1bc5a-c0aa-4d9f-b179-abc68dfaceaa"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n\\nMichael Taylor on his own behalf', '\\n\\nMichael Taylor on his own behalf\\nWade McBride, K.C.', \" and Carlene Ready for the Respondent\\nLisa Watson for Saskatchewan Lawyers' Insurance Association Inc\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_lines_after_counsel(s):\n",
        "    # Split the string at \"Counsel:\"\n",
        "    parts = s.split('Counsel:', 1)\n",
        "\n",
        "    # If there's no \"Counsel:\" or nothing after it, return an empty list\n",
        "    if len(parts) < 2:\n",
        "        return []\n",
        "\n",
        "    # Split the remaining string by lines and strip whitespace from each line\n",
        "    lines = [line.strip() for line in parts[1].split('\\n')]\n",
        "\n",
        "    # Filter out empty lines\n",
        "    lines = [line for line in lines if line]\n",
        "\n",
        "    # Process each line to split on \"and\" if necessary and keep lines with \"for\"\n",
        "    final_lines = []\n",
        "    for line in lines:\n",
        "        if \" for \" in line:\n",
        "            names = line.split(\" and \")\n",
        "            if len(names) > 1:\n",
        "                for_clause = names[-1].split(\" for \", 1)[-1]  # e.g., \"the Appellant\"\n",
        "                for name in names:\n",
        "                    if \" for \" not in name:\n",
        "                        final_lines.append(name.strip() + \" for \" + for_clause)\n",
        "                    else:\n",
        "                        final_lines.append(name.strip())\n",
        "            else:\n",
        "                final_lines.append(line)\n",
        "\n",
        "    return final_lines\n",
        "\n",
        "# Test\n",
        "s = \"\"\"Counsel:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Brian Pfefferle, K.C. and Thomas Hynes for the Appellant\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Michael Nolin for the Respondent\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Jackson J.A.\n",
        "\n",
        "# I.                  Introduction\"\"\"\n",
        "\n",
        "print(extract_lines_after_counsel(s))\n"
      ],
      "metadata": {
        "id": "D5X0i2Z_iB16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c285d88-1dd8-4522-aa5d-ffaa38e00a36"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Brian Pfefferle, K.C. for the Appellant', 'Thomas Hynes for the Appellant', 'Michael Nolin for the Respondent']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Woef2Thlfo9a"
      },
      "execution_count": 52,
      "outputs": []
    }
  ]
}